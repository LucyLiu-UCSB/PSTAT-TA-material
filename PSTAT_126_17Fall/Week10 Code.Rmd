---
title: "Week10 Code"
author: "Lucy Liu"
date: "12/5/2017"
output: 
  html_document:
    number_sections: yes
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE,fig.align = "center"
                      ,fig.height=4,fig.width=8)
```

# Outliers test

##  Theory of the outlier test

* Null hypothesis:   
$H_0: \delta_i=0$ i.e. $Y_i$ is NOT an outlier.  
$H_1: \delta_i \neq 0$ i.e. $Y_i$ is  an outlier.
        
* Test statistic:
  $$t_i=\frac{Y_i-\hat{Y}_{i(i)}}{\hat{\sigma}_{(i)}\sqrt{1+x_i^T(X_{(i)}^TX_{(i)}^{-1})x_i}}$$
  or
  $$t_i=r_i\left(\frac{n-p-2}{n-p-1-r_i^2}\right)^{1/2}$$
  where $r_i=\frac{e_i}{\hat{\sigma}\sqrt{1-h_{ii}}}$ is standardized residual.

* Distribution of $t_i$ under $H_0$
$$t_i\sim t_{n-p-2}$$

***Note: one critical issue is that outliers test involves multiple testing problem.=>Bonferroni Correction ***

## Application

Simulation Setting:

 $$\text{Weight}_i=10+0.45*\text{Height}_i+\varepsilon_i,\qquad \varepsilon_i\sim N(0,5^2), i= 2,\ldots,100$$
For the first observation: $\text{Weight}_1=14+10+0.45*\text{Height}_1+\varepsilon_1, \varepsilon_1\sim N(0,5^2)$, which means Weight$_1$ is an outlier.
```{r}
### A simulation to check the influence of sample size in outliers test
library(alr4)
# when sample size n =100
set.seed(20171206)
height<-rnorm(100, mean = 170, sd = 10)
weight<-height*0.45+10+rnorm(100, mean = 0, sd = 5)
weight[1]<-107
dataframe.n100<-data.frame(Weight=weight,Height=height)
lm.n100 <-lm( Weight~. , data = dataframe.n100)
outlierTest(lm.n100)
```

```{r}
# when sample size n =1000
set.seed(20171206)
height.new<-c(height,rnorm(900, mean = 170, sd = 10))
weight.new<-c(weight,height.new[101:100]*0.45+10+rnorm(900, mean = 0, sd = 5))
dataframe.n1000<-data.frame(Weight=weight.new,Height=height.new)
lm.n1000 <-lm( Weight~. , data = dataframe.n1000)
outlierTest(lm.n1000)
```

* Base on the first test, Bonferroni $p = 0.0011864$ < $\alpha=0.05$ = > reject $H_0$ = > There might be outliers in Y.

* Base on the second test, Bonferroni $p =  0.12523$ > $\alpha=0.05$ = > fail to reject $H_0$ = > There is no outlier in Y.

The reason is that when sample size is large, Bonferroni correction tends to pay too much attention on Type I error. In your project, you may further check Cook distance even if you fail to reject $H_0$ in the outlier test. 



# Weighted least square and nonconstant variance test


## Theory of  nonconstant variance test

* Null hypothesis:     
$H_0$: Constant variance  
$H_1$: Nonconstant variance
        
* Test statistic: $S$ (score test)
  
  
* Distribution of $S$ under $H_0$:
$$S\sim \chi_q^2$$

## Application ---`ncvTest`

### Case 1: $\sigma_i^2=E^2(Y_i), w_i=1/\sigma_i^2$

Simulation Setting(True model)

$$Y_i=1+2*x_i+\varepsilon_i,\qquad\varepsilon_i\sim N(0,E(Y_i)^2),\quad i=1,\cdots,100 $$

```{r}
#######################    Case 1:  H1: w_i = 1/|y_i|^2       #######################
set.seed(20171205)
x<-rnorm(100,mean=runif(100,0,1),sd = 4)
mean.y<-1+x*2
### \sigma_i= abs(E(y_i))
y<-mean.y+rnorm(100,mean = 0, sd=abs(mean.y))
dataframe.sigma.y<-data.frame(Y=y,X=x)
fit.weightY<-lm(Y~., data = dataframe.sigma.y)
plot(fit.weightY, which = 3)
### noncanstant variance test
ncvTest(fit.weightY, ~abs(Y))
### weighted least square
fit.wls.Y<-lm(Y~., weight=1/Y^2, data = dataframe.sigma.y)
plot(fit.wls.Y, which = 3)
```

### Case 2: $\sigma_i= x_i^2, w_i= 1/\sigma_i^2$

Simulation Setting(True model)

$$Y_i=1+2*x_i+3*z_i+\varepsilon_i,\qquad\varepsilon_i\sim N(0,x_i^2),\quad i=1,\cdots,100 $$
```{r,fig.width=10}
#######################    Case 2 H1: w_i = |y_i|          #######################
set.seed(20171205)
x<-rnorm(n = 100,mean = runif(100,0,2),sd=4)
z<-rnorm(n=100,mean=rnorm(100,3,2),sd=3)
Y<-1+2*x+3*z+rnorm(100,mean = 0,abs(x))
dataframe.sigma.x<-data.frame(Y=Y,X=x,Z=z)
ordinary.lm<-lm(Y~., data= dataframe.sigma.x)
residual.ordinary<-resid(ordinary.lm)
par(mfrow=c(1,3))
attach(dataframe.sigma.x)
plot(fitted(ordinary.lm),residual.ordinary,col=2,main="e_i vs Y_i.hat")
plot(x,residual.ordinary,col=3,main = "e_i vs x_i")
plot(z,residual.ordinary,col=4,main = "e_i vs z_i")
```
```{r,fig.height=4,fig.width=4}
par(mfrow=c(1,1))
plot(ordinary.lm,which=2)
#######################     Noncanstant variance test         #######################
ncvTest(ordinary.lm, ~X) # Just x
ncvTest(ordinary.lm, ~Z) # Just z
ncvTest(ordinary.lm, ~Z+X) # x and z
1 - pchisq(103.1691 - 102.1573, 1) # p-value for test if we can just use x 
```
P-value = 0.314472< 0.05 = > fail to reject $H_0:\sigma_i\sim \lambda_x x_i+\lambda_z z_i, \lambda_z=0$. We can just use $1/x^2$ as weight in least square estimation.  






```{r,fig.width=10}
#######################    Fit weighted least square          #######################
weighted.ls<-lm(Y~., data =  dataframe.sigma.x, weights = 1/X^2)
residual.wls<-resid(weighted.ls)
par(mfrow=c(1,3))
plot(fitted(weighted.ls),residual.wls,col=2,main="e_i vs Y_i.hat")
plot(x,residual.wls,col=3,main = "e_i vs x_i")
plot(z,residual.wls,col=4,main = "e_i vs z_i")
detach(dataframe.sigma.x)
```

```{r,fig.height=4,fig.width=4}
par(mfrow=c(1,1))
plot(weighted.ls,which=2)
```


